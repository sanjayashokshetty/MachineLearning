{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "data=pd.read_csv('SPECT.csv')\n",
    "data=np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=len(data[0])-1\n",
    "n_data=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris-setosa\n",
    "for i in range(n_data):\n",
    "    if(data[i][n_features]==\"Yes\"):\n",
    "        data[i][n_features]=1\n",
    "    else:\n",
    "        data[i][n_features]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold no: 0\n",
      "testTT: 15  testTF: 4  testFF: 3  testFT: 4\n",
      "test_accuracy 69.23074260356053 %\n",
      "test Precision +: 78.94732686982796 %\n",
      "test Precision -: 42.85708163274053 %\n",
      "test recall +: 78.94732686982796 %\n",
      "test recall -: 42.85708163274053 %\n",
      "fold no: 1\n",
      "testTT: 17  testTF: 5  testFF: 2  testFT: 2\n",
      "test_accuracy 73.07689497042502 %\n",
      "test Precision +: 89.47363711913836 %\n",
      "test Precision -: 28.571387755160348 %\n",
      "test recall +: 77.2726921487763 %\n",
      "test recall -: 49.99987500031251 %\n",
      "fold no: 2\n",
      "testTT: 20  testTF: 0  testFF: 3  testFT: 3\n",
      "test_accuracy 88.46150443788291 %\n",
      "test Precision +: 86.95648393196352 %\n",
      "test Precision -: 99.99966666777777 %\n",
      "test recall +: 99.99995000002501 %\n",
      "test recall -: 49.99991666680556 %\n",
      "fold no: 3\n",
      "testTT: 21  testTF: 1  testFF: 2  testFT: 2\n",
      "test_accuracy 88.46150443788291 %\n",
      "test Precision +: 91.30430812856169 %\n",
      "test Precision -: 66.66644444518518 %\n",
      "test recall +: 95.45450206613543 %\n",
      "test recall -: 49.99987500031251 %\n",
      "fold no: 4\n",
      "testTT: 20  testTF: 0  testFF: 1  testFT: 5\n",
      "test_accuracy 80.76919970415396 %\n",
      "test Precision +: 79.9999680000128 %\n",
      "test Precision -: 99.99900000999989 %\n",
      "test recall +: 99.99995000002501 %\n",
      "test recall -: 16.666638888935186 %\n",
      "fold no: 5\n",
      "testTT: 16  testTF: 3  testFF: 7  testFT: 0\n",
      "test_accuracy 88.46150443788291 %\n",
      "test Precision +: 99.99993750003907 %\n",
      "test Precision -: 69.99993000007 %\n",
      "test recall +: 84.21048199448316 %\n",
      "test recall -: 99.99985714306123 %\n",
      "fold no: 6\n",
      "testTT: 19  testTF: 1  testFF: 3  testFT: 3\n",
      "test_accuracy 84.61535207101844 %\n",
      "test Precision +: 86.36359710745586 %\n",
      "test Precision -: 74.99981250046875 %\n",
      "test recall +: 94.99995250002375 %\n",
      "test recall -: 49.99991666680556 %\n",
      "fold no: 7\n",
      "testTT: 18  testTF: 3  testFF: 2  testFT: 3\n",
      "test_accuracy 76.92304733728949 %\n",
      "test Precision +: 85.71424489797862 %\n",
      "test Precision -: 39.99992000016 %\n",
      "test recall +: 85.71424489797862 %\n",
      "test recall -: 39.99992000016 %\n",
      "fold no: 8\n",
      "testTT: 19  testTF: 4  testFF: 2  testFT: 1\n",
      "test_accuracy 80.76919970415396 %\n",
      "test Precision +: 94.99995250002375 %\n",
      "test Precision -: 33.33327777787037 %\n",
      "test recall +: 82.60865973536534 %\n",
      "test recall -: 66.66644444518518 %\n",
      "fold no: 9\n",
      "testTT: 19  testTF: 7  testFF: 5  testFT: 2\n",
      "test_accuracy 72.7272506887119 %\n",
      "test Precision +: 90.47614739231076 %\n",
      "test Precision -: 41.66663194447338 %\n",
      "test recall +: 73.07689497042502 %\n",
      "test recall -: 71.42846938790089 %\n",
      "average result for  10 fold\n",
      "test_accuracy 80.34962003929621 %\n",
      "test Precision +: 88.42356034473123 %\n",
      "test Precision -: 59.80931527339063 %\n",
      "test recall +: 87.22846551830656 %\n",
      "test recall -: 53.76179948322191 %\n"
     ]
    }
   ],
   "source": [
    "thresold=0.5\n",
    "n_epochs=1000\n",
    "learning_rate=0.5\n",
    "k_fold=10\n",
    "layer=[n_features,5,1]\n",
    "bias=[[1/layer[i+1]]*layer[i+1] for i in range(len(layer)-1)]\n",
    "nodes=[[0]*layer[i] for i in range(len(layer))]\n",
    "error=[[0]*layer[i] for i in range(len(layer))]\n",
    "\n",
    "#kfold variables\n",
    "width=int(n_data/k_fold)\n",
    "k_fold_index=[]\n",
    "start=0\n",
    "for i in range(k_fold-1):\n",
    "    k_fold_index.append([start,start+width])\n",
    "    start=start+width\n",
    "k_fold_index.append([start,n_data])\n",
    "\n",
    "def retweights():\n",
    "    weights=[[[1/(layer[i]*layer[i+1])]*layer[i] for j in range(layer[i+1])] for i in range(len(layer)-1)]\n",
    "    return weights\n",
    "\n",
    "def kfolddata(j,data):\n",
    "    x_test=data[k_fold_index[j][0]:k_fold_index[j][1],0:n_features]\n",
    "    y_test=data[k_fold_index[j][0]:k_fold_index[j][1],n_features]\n",
    "    if(j+1<=9):\n",
    "        x_train=data[k_fold_index[j][1]:,0:n_features]\n",
    "        y_train=data[k_fold_index[j][1]:,n_features]\n",
    "        if(j-1!=-1):\n",
    "            x_train=np.append(x_train,data[0:k_fold_index[j][0],0:n_features],axis=0)\n",
    "            y_train=np.append(y_train,data[0:k_fold_index[j][0],n_features],axis=0)\n",
    "    else:\n",
    "        x_train=data[0:k_fold_index[j][0],0:n_features]\n",
    "        y_train=data[0:k_fold_index[j][0],n_features]\n",
    "    return x_train,y_train,x_test,y_test\n",
    "    \n",
    "def function(row,nodes,weights,bias,thresold,layer):\n",
    "    for i in range(len(row)):\n",
    "        nodes[0][i]=row[i]\n",
    "    for lay in range(1,len(layer)):\n",
    "        for j in range(layer[lay]):\n",
    "            y=bias[lay-1][j]\n",
    "            for prevlayer,k in enumerate(weights[lay-1][j]):\n",
    "                y=y+nodes[lay-1][prevlayer]*k\n",
    "            nodes[lay][j]=1.0/(1.0+math.exp(-y))\n",
    "    if(nodes[len(layer)-1][0]>=thresold):\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "    return nodes,y\n",
    "\n",
    "def back_prop(weights,nodes,total_error,thresold,bias,learning_rate,cost,error,z):\n",
    "    #output layer error\n",
    "    error[len(error)-1][0]=(z-nodes[len(error)-1][0])*(1-nodes[len(error)-1][0])*nodes[len(error)-1][0]\n",
    "    #hidden layers\n",
    "    total_error+=abs(error[len(error)-1][0])\n",
    "    for lay in range(len(error)-2,0,-1):\n",
    "        for nod in range(len(nodes[lay])):\n",
    "            err=0\n",
    "            for nxtlaynod in range(len(nodes[lay+1])):\n",
    "                err+=error[lay+1][nxtlaynod]*weights[lay][nxtlaynod][nod]             \n",
    "            error[lay][nod]=nodes[lay][nod]*(1-nodes[lay][nod])*err\n",
    "    #update weights\n",
    "    for lay in range(len(weights)):\n",
    "        for j in range(len(weights[lay])):\n",
    "            for i in range(len(weights[lay][j])):\n",
    "                weights[lay][j][i]+=learning_rate*nodes[lay][i]*error[lay+1][j]\n",
    "    for lay in range(len(bias)):\n",
    "        for i in range(len(bias[lay])):\n",
    "            bias[lay][i]+=learning_rate*error[lay+1][i]\n",
    "    return weights,bias,total_error\n",
    "\n",
    "from valid import validation\n",
    "foldres=validation.foldwise()\n",
    "\n",
    "for fold in range(k_fold):\n",
    "    print(\"fold no:\",fold)\n",
    "    x_train,y_train,x_test,y_test=kfolddata(fold,data)\n",
    "    weights=retweights()\n",
    "    foldres.reset()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_error=0\n",
    "        for i in range(len(x_train)):\n",
    "            nodes,y=function(x_train[i],nodes,weights,bias,thresold,layer)\n",
    "            z=y_train[i]\n",
    "            cost=z-y\n",
    "            weights,bias,total_error=back_prop(weights,nodes,total_error,thresold,bias,learning_rate,cost,error,z)\n",
    "#         print(\"epoch\",epoch,\"error\",total_error)\n",
    "    for i in range(len(x_test)):\n",
    "        nodes,y=function(x_test[i],nodes,weights,bias,thresold,layer)\n",
    "        z=y_test[i]\n",
    "        cost=z-y\n",
    "        foldres.valid(y,cost,1)\n",
    "    foldres.printfoldresult()\n",
    "    foldres.averageresults() \n",
    "foldres.printaverageresults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
